<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
</head>
<body>
<h1 id="ecological-forecasting-workshop">Ecological Forecasting Workshop</h1>
<h2 id="workflows-breakout-group">Workflows breakout group</h2>
<p>Target audience and scope would be scientists, developers and funders aiming to contribute to these key areas in ecological forecasting to remind them that they should consider developing the state of the art in our ability to act interoperably and reproduibly in those areas... so that they may adopt some of our recommendations.</p>
<h3 id="summary-after-meeting-1-and-whole-group-discussion">SUMMARY AFTER MEETING 1 AND WHOLE GROUP DISCUSSION</h3>
<p>Discussion focused on * Needs from workflow engines in the future * Why we haven't adopted a common workflow system * Standardising across data formats and model input output formats * Benchmarking models against multiple datasets * Model intercomparisons * Red flag systems for when data and model outputs are differing from expected behaviours * Adding semantics to model and data inputs and outputs and probabilities * Metadata standards that will work for ecological forecasting</p>
<p>Reproducibility - would motivate adoption; esp. if demanded by journals, funding, reviewers; Review Paper topics * state of reproducibiilty * best practices data life cycle</p>
<h3 id="notes-made-during-meeting-1">NOTES MADE DURING MEETING 1</h3>
<ul>
<li>Topics</li>
<li>Metadata/data standardization and interoperability
<ul>
<li>how to define and share probabilistic results?</li>
<li>easier to describe 'data' than model output</li>
</ul></li>
<li>rOpenSci Getting data into R: what do workflows need?
<ul>
<li>How can we standardize data formats?</li>
<li>EML (ecological metadata language), NeXML (http://www.nexml.org/)</li>
<li>estimates of uncertainty / data quality</li>
<li>uniform API for multiple sources of data - we're working on this, so far we have</li>
<li>taxonomy (from e.g., NCBI, ITIS, etc.)</li>
<li>spatial data (from e.g. GBIF, BISON, iNaturalist, etc.)</li>
<li>EML package: can automatically push data and get do</li>
<li>Push to KNB/DataONE/FigShare repositories</li>
<li>R package eml: https://github.com/ropensci/EML</li>
<li>Would it help to write out netcdf files from our NOAA R pkg wrapper to use in other software? And for spatial occurrence data from spocc/rgbif/etc?</li>
<li>Data transformations we could provide? e.g, Interpolation of climate data from NOAA</li>
</ul></li>
<li>Kepler modules as frontend to R code</li>
<li>Automated provenance tracking w/in R (e.g. analytic web)</li>
<li>Parallelization of code; access to different scheduler engines; evolving landscape</li>
<li>Workflow branches based on needs of node (e.g. I/O, flops, ram)
<ul>
<li>helps w/ scalability.</li>
</ul></li>
<li>Uncertainty, multi-scale coupling
<ul>
<li>how to couple independent codes; model-to-model coupling; transformation</li>
</ul></li>
<li>Why one workflow system over another;
<ul>
<li>what are common and uncommon requirements for workflow engines</li>
<li>What do we want in a wf engine;</li>
<li>See comparison paper:</li>
<li>Yu, Jia, and Rajkumar Buyya. &quot;A taxonomy of scientific workflow systems for grid computing.&quot; ACM Sigmod Record 34.3 (2005): 44-49.http://arxiv.org/pdf/cs/0503025.pdf</li>
<li></li>
<li>2007 workshop: taverna, triana, kepler. Covered this question - decided that interoperability was more trouble than it is worth; compatability done by wraping one in another.</li>
</ul></li>
<li>Invitro modeling framework (a workflow?) - model interoperability
<ul>
<li>modularity - componentize complexity</li>
<li>Ptolemy: Models of computation</li>
<li>See: Lee, E. A., and A. Sangiovanni-Vincentelli. 1998. A framework for comparing models of computation. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 17:1217–1229. doi:10.1109/43.736561<br /></li>
</ul></li>
<li>The problem of the computational overhead in using workflows</li>
<li>Developing worksflow models for data-constrained models of systems.</li>
<li>Benefit from having a large enough project to work with
<ul>
<li>e.g bioinformatics -&gt; bioKepler</li>
<li>openTopography.org</li>
</ul></li>
<li>R as a workflow itself - this is essentially folks using knitr with markdown or latex - which has very little structure other than separating text from code blocks</li>
<li>Finite state machine as model to model communication</li>
<li>UVCDat http://uvcdat.llnl.gov/</li>
<li>Bob Cook: MstMIP / model intercomparison</li>
<li>MODEL INTERCOMPARISONS &lt;- one of the key areas of future application</li>
<li>Anticipate key workflow/software needs for 5-10 years time</li>
<li>Workflows as a means to get the community to work together</li>
<li>If ecological forecasting is to become a reality - we need workflows to deliver that</li>
<li>Model component interoperation - going from molecules to blue whales</li>
<li>Models (and model components) as hypotheses</li>
<li>Benchmarking models &lt;- a perfect place for workflows</li>
<li>Scenario testing</li>
<li>Having WF system handle uncertainty would be useful</li>
<li>Need mechanism to represent model outputs and model performance</li>
<li>Identify translators for model inputs &amp; outputs</li>
<li>e.g. Adopt MSTMIP standards for variables</li>
<li>merging across scales</li>
<li>end to end modeling -&gt; is there any meaning to this?
<ul>
<li>Beth Fulton, Ken Rose</li>
<li>don't do it; not sufficiently adaptable</li>
<li>keep it simple, solve one prob. at a time</li>
<li>keep data in native format rather than homogenize</li>
</ul></li>
<li>What are the low hanging fruit?</li>
<li>Optimal levels of complexity in workflow
<ul>
<li>also, model complexity</li>
</ul></li>
<li>Detection of scale shifts, using scale as object of observation
<ul>
<li>Auto characterisation of sig changes in ecological data and model predictions. Identifying red flags in data observations and model predictions</li>
</ul></li>
<li>Transparent / efficient access to data, computing &lt;- ability to combine both in a transparent way</li>
<li>provenance tracking -&gt; captured as reproducible research objects</li>
<li>adopting best practices w/in community</li>
<li>business model to sustain software; combining big, heterogeneous data,</li>
<li>Lack of willing in community to adopt modularity in multicomponent models of systems</li>
<li>Managing data streams &lt;- big data</li>
<li>Managing large volumes of data &lt; big data</li>
<li>Big data IS an issue in certaiin areas</li>
<li>What are the workflow needs for the next 5-10 years
<ul>
<li>learnn from past efforts and lessons</li>
<li>Look towards future demands</li>
</ul></li>
<li>Data integration and model coupling
<ul>
<li>almost all existing systems don't deal in semantics</li>
<li>Try to add semantics to modelling frameworks to make it easier to build systems that understand more of the data / information compatabilities specific to the domain.</li>
</ul></li>
</ul>
<h2 id="day-2-discussion">Day 2 Discussion</h2>
<ul>
<li>Why have so many groups decided to create their own workflow rather than adapt an existing system?</li>
<li>Are ecological demands on wf systems special?</li>
<li>Can we describe model components semantically to provide plug-n-play within wf systems?<br /></li>
<li>Berkley, C., S. Bowers, M. B. Jones, B. Ludaescher, M. Schildhauer, and J. Tao. 2005. Incorporating Semantics in Scientific Workflow Authoring. Pages 75–78 in J. Frew, editor. Proceedings of the 17th International Conference on Scientific and Statistical Database Management. Santa Barbara, CA.</li>
<li>Madin, J., S. Bowers, M. Schildhauer, S. Krivov, D. Pennington, and F. Villa. 2007. An ontology for describing and synthesizing ecological observation data. Ecological Informatics 2:279–296.</li>
<li>Madin, J. S., S. Bowers, M. P. Schildhauer, and M. B. Jones. 2008. Advancing ecological research with ontologies. Trends in Ecology &amp; Evolution 23:159–68.</li>
<li>What are the key barriers to plug-n-play ecological forecasting?</li>
<li>Getting data providers online to not only provide read, but also write access through open APIs</li>
<li>Provide mechanism to describe a desired standard data product
<ul>
<li>Can be the target of data transformation as input to a model, or can describe existing raw data to decide which are transformable to that target</li>
</ul></li>
<li>Licenses? (e.g., ESA ecological archives has unclear licenses for reuse)</li>
<li>Lack of well-specified interfaces to model components; Standard grammars for defining data-data and data-model and model-model interfaces</li>
</ul>
<p>&quot;Best practices in ecological computing&quot;</p>
<ul>
<li>in R: Commit to S4 classes instead of S3, all languages: well-specified APIs, contractual committment</li>
<li>continuous integration e.g. Travis-CI (or is this too high level?)</li>
<li>testing (too high level?)</li>
<li></li>
</ul>
<p>What do we need to do to up our game, computationally, in producing actionable predictions of ecosystems - data input standards, workflows, probabilities, cloud</p>
<p>Proposal of what to work on</p>
<ol style="list-style-type: decimal">
<li>High profile perspective on the needs to get towards reproducibility in the prediction of complex multicomponent systems - for which ecological systems are a prime example but Earth System Models are another - and how advances in workflow technology are needed to achieve that - potentially with a section on case study examples of where we really need this reproducibility in order to keep advancing. Tailed by 5-10 year goal for the development of workflow technology to meet the needs of ecological / earth system research.</li>
<li>Discuss further how the specifics of conducting multicomponent multi-dataset inference based research raises new challenges for developing workflows.</li>
<li>Discuss the challenges of managing multi-component modelling with workflows</li>
<li>A semantics for decribing workflows? Needed? Helpful?</li>
</ol>
<p>Publishing derived data sets. Automated data input and output (e.g. what NEON is working on)</p>
<p>ncML -</p>
<p>Top 10 blockers/necessary developments to plug-and-play ecosystem forecasting: key development requirements for the next 5-10 years</p>
<p>Achieving greater levels of interoperability:</p>
<h2 id="paper-outline">Paper Outline</h2>
<p>Titles:</p>
<ul>
<li>&quot;Reproducibility in ecological and environmental modelling: whether and why scientific workflows, and where next?&quot;</li>
<li><p>&quot;Software practices that promote interoperability {and reproducibility} for ecological forecasting&quot;</p></li>
<li>rhetorical approach framework</li>
<li>name and define practice</li>
<li>what do you want to achieve and how to get there</li>
<li>pros and cons</li>
<li><p>examples</p></li>
</ul>
<p>Outline/Topics</p>
<ul>
<li>Intro general background of sw best practices (e.g., White paper), plus acknowledge these are well-established software engineering practices</li>
<li>Discussion of desiridata: Reproducible, Traceable, Usable, Comparable, {Reusable}</li>
<li>define the terms</li>
<li>why are they useful
<ul>
<li>within context of increasing applied relevance</li>
<li>increased efficiency within research groups</li>
<li>building community: standing on shoulders of giants</li>
</ul></li>
<li>Recommended Practices (pros, cons/limitations, benefits, example of use); presented in heirarchy of stages ...</li>
<li>Version and archive and share code
<ul>
<li>Gists versus repos versus releases</li>
</ul></li>
<li>Use Functions: abstract and generalize, DRY
<ul>
<li>Example from eco forecasting</li>
</ul></li>
<li>Well-specified interfaces (APIs) and modules
<ul>
<li>Consistent contracts between modules</li>
<li>Hooks for other software to interact</li>
<li>Version control of APIs and modules</li>
<li>Example from eco forecasting</li>
</ul></li>
<li>Avoid letting implementation leak into interface
<ul>
<li>e.g., JAGS requires integer site names for iteration, constraining data inputs</li>
<li>e.g., weather downscaling algorithm that works based on column order or specific naming conventions</li>
</ul></li>
<li>Automate data processing (not in Excel)
<ul>
<li>Auditable, repeatable</li>
<li>Example</li>
</ul></li>
<li>De-couple data from code: use data repository APIs, use open, portable data representation formats {like CSV, and NetCDF}
<ul>
<li>No hard coded paths</li>
<li>Isolate data I/O in separate modules (e.g., a) call to the web, collect raw payload, b) downstream processing)</li>
<li>References to data in <em>accessible</em> repository systems (e.g., via DOI)</li>
<li>Deal with access control issues (public versus private examples)</li>
<li>Version control of data (e.g., DataONE, dat, ...)</li>
<li>See diatribes about reasons to share data</li>
<li>Example from eco forecasting</li>
</ul></li>
<li>Use a consistent error handling and propagation strategy</li>
<li>Use composable workflow systems (e.g., R, Kepler) to link components
<ul>
<li>Benefit: reuse and mix and match modules for various applications</li>
<li>Benefit -- documents end-to-end process</li>
<li>Example: Benefit of Automation: show LeBauer example of automation</li>
</ul></li>
<li>Document the workflow and process and code
<ul>
<li>Use literate programming to link implementation to documentation</li>
<li>Doxygen, ROxygen, knitr</li>
<li>write for humans; clear variable names</li>
</ul></li>
<li>{Provide License and metadata} - or can we ref this in other papers?</li>
<li>Formally test models
<ul>
<li>Separate unit and integration testing</li>
<li>Test with a wide variety of data bounds / prevent decline of model skill</li>
</ul></li>
<li>Be aware of scaling and integration choices, use broker/wrapper components to couple components that operate at multiple scales or rates
<ul>
<li>Expose module constraints in documentation</li>
<li>e.g., scale constraints, normality constraints, etc.</li>
</ul></li>
<li>Report uncertainty in input and output data
<ul>
<li>Can we recommend specific uncertaininty representations, or at least list them?</li>
<li>A typology of uncertainty measures, with a serialization approach</li>
</ul></li>
<li>Education/Workforce dev and Collaboration topics?</li>
<li>Need to train EES students e.g., software carpentry as starting point</li>
<li>Build on this with the best practices</li>
<li>Error handling (See recommendation above -- should this be in the recs section?)</li>
<li>useful messages</li>
<li>examples and/or case studies (or integrated into practices above)</li>
</ul>
<h2 id="references">References</h2>
<p>CF Standards - NetCDF metadata standards for data discovery: https://geo-ide.noaa.gov/wiki/index.php?title=NetCDF_Attribute_Convention_for_Dataset_Discovery</p>
<p>Mandal, N., E. Deelman, G. Mehta, M.-H. Su, K. Vahi, and M. D. Rey. 2007. Integrating Existing Scientific Workflow Systems : The Kepler / Pegasus Example. Information Sciences:21–28.</p>
<p>Wang, J., I. Altintas, C. Berkley, L. Gilbert, and M. B. Jones. 2008. A High-Level Distributed Execution Framework for Scientific Workflows. 2008 IEEE Fourth International Conference on eScience:634–639.</p>
<p>Wang, J., I. Altintas, P. R. Hosseini, D. Barseghian, D. Crawl, C. Berkley, and M. B. Jones. 2009. Accelerating Parameter Sweep Workflows by Utilizing Ad-hoc Network Computing Resources: An Ecological Example. 2009 Congress on Services - I:267–274.</p>
<p>Allen Hierarchy: Perspectives for Ecological Complexity</p>
<p>http://blogs.msdn.com/b/martinca/archive/2009/11/02/microsoft-computational-science-studio.aspx</p>
<p>Coming Soon to a Lab Near You: Drag-and-Drop Virtual Worlds</p>
<ul>
<li>Robert F. Service</li>
<li>Science 11 February 2011: 669-671. [DOI:10.1126/science.331.6018.669]</li>
</ul>
<p>An example of a similar &quot;guidelines&quot; paper; outreach rather than findings:<br />Borer, E., E. Seabloom, M. B. Jones, and M. Schildhauer. 2009. Some Simple Guidelines for Effective Data Management. Bulletin of the Ecological Society of America:205–214. http://dx.doi.org/10.1890/0012-9623-90.2.205</p>
<p>An example of using global change to illustrate changes needed in data management:<br />Wolkovich, E. M., J. Regetz, and M. I. O’Connor. 2012. Advances in global change research require open science by individual researchers. Global Change Biology:1–9. doi:10.1111/j.1365-2486.2012.02693.x</p>
</body>
</html>
